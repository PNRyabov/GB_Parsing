# Курс "Методы сбора и обработки данных из сети Интернет"

### **Занятие 1:**

В качестве домашнего задания необходимо:

1. Посмотреть документацию к [API GitHub](https://docs.github.com/en/rest), разобраться как вывести список репозиториев для конкретного пользователя, сохранить JSON-вывод в файле *.json.
2. Изучить список открытых API (https://www.programmableweb.com/category/all/apis). Найти среди них любое, требующее авторизацию (любого типа). Выполнить запросы к нему, пройдя авторизацию. Ответ сервера записать в файл. Если нет желания заморачиваться с поиском, возьмите API вконтакте (https://vk.com/dev/first_guide). Сделайте запрос, чтобы получить список всех сообществ на которые вы подписаны.

### **Занятие 2:**

Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы получаем должность) с сайтов [HH](https://hh.ru/). Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:
* Наименование вакансии.
* Предлагаемую зарплату (разносим в три поля: минимальная и максимальная и валюта. цифры преобразуем к цифрам).
* Ссылку на саму вакансию.
* Сайт, откуда собрана вакансия.
* По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas. Сохраните в json либо csv.

### **Занятие 3:**

Спарсить цитаты с сайта Quotes to Scrape - https://quotes.toscrape.com.
Необходимо извлечь: цитаты, авторов и список тегов.
Задание со звёздочкой: спарсить все цитаты на сайте, а не только с первой страницы.
При парсинге желательно использовать разные методы для получения необходимой информации.

### **Занятие 4:**

1. Создать [MongoDB](https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-os-x/), записать туда данные из парсера с предыдущего урока (любое название базы, любое название таблицы). Выполнить команду для демонстрации содержимого коллекции. Прикрепить скриншот.
2. Создать базу данных sqlite, загрузить туда данные из парсера с предыдущего урока. Загрузить файл .db

### **Занятие 5:**

В качестве домашнего задания необходимо провести парсинг сайта https://scrapingclub.com/exercise/list_basic/ .
Нам потребуется пройтись по каждой странице товара и собрать следующую информацию:
* название,
* цену,
* описание,
* картинку.
 
Используем [SCRAPY](https://docs.scrapy.org/en/latest/index.html).
